{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# coding=utf8\n",
        "\n",
        "\"\"\"\n",
        "Deeply-Recursive Convolutional Network for Image Super-Resolution\n",
        "Paper: http://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Kim_Deeply-Recursive_Convolutional_Network_CVPR_2016_paper.html\n",
        "\n",
        "Test implementation model\n",
        "Author: Jin Yamanaka\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import super_resolution_utilty as util\n",
        "\n",
        "\n",
        "class DataSet:\n",
        "\tdef __init__(self, cache_dir, filenames, channels=1, scale=1, alignment=0, jpeg_mode=False, max_value=255.0):\n",
        "\n",
        "\t\tself.count = len(filenames)\n",
        "\t\tself.image = self.count * [None]\n",
        "\n",
        "\t\tfor i in range(self.count):\n",
        "\t\t\timage = util.load_input_image_with_cache(cache_dir, filenames[i], channels=channels,\n",
        "\t\t\t                                         scale=scale, alignment=alignment, jpeg_mode=jpeg_mode)\n",
        "\t\t\tself.image[i] = image\n",
        "\n",
        "\tdef convert_to_batch_images(self, window_size, stride, max_value=255.0):\n",
        "\n",
        "\t\tbatch_images = self.count * [None]\n",
        "\t\tbatch_images_count = 0\n",
        "\n",
        "\t\tfor i in range(self.count):\n",
        "\t\t\timage = self.image[i]\n",
        "\t\t\tif max_value != 255.0:\n",
        "\t\t\t\timage = np.multiply(self.image[i], max_value / 255.0)\n",
        "\t\t\tbatch_images[i] = util.get_split_images(image, window_size, stride=stride)\n",
        "\t\t\tbatch_images_count += batch_images[i].shape[0]\n",
        "\n",
        "\t\timages = batch_images_count * [None]\n",
        "\t\tno = 0\n",
        "\t\tfor i in range(self.count):\n",
        "\t\t\tfor j in range(batch_images[i].shape[0]):\n",
        "\t\t\t\timages[no] = batch_images[i][j]\n",
        "\t\t\t\tno += 1\n",
        "\n",
        "\t\tself.image = images\n",
        "\t\tself.count = batch_images_count\n",
        "\n",
        "\t\tprint(\"%d mini-batch images are built.\" % len(self.image))\n",
        "\n",
        "\n",
        "class DataSets:\n",
        "\tdef __init__(self, cache_dir, filenames, scale, batch_size, stride_size, width=0, height=0, channels=1,\n",
        "\t             jpeg_mode=False, max_value=255.0):\n",
        "\t\tself.input = DataSet(cache_dir, filenames, channels=channels, scale=scale, alignment=scale, jpeg_mode=jpeg_mode)\n",
        "\t\tself.input.convert_to_batch_images(batch_size, stride_size, max_value=max_value)\n",
        "\n",
        "\t\tself.true = DataSet(cache_dir, filenames, channels=channels, alignment=scale, jpeg_mode=jpeg_mode)\n",
        "\t\tself.true.convert_to_batch_images(batch_size, stride_size, max_value=max_value)\n",
        "\n",
        "\n",
        "class SuperResolution:\n",
        "\tdef __init__(self, flags, model_name=\"model\"):\n",
        "\n",
        "\t\t# Model Parameters\n",
        "\t\tself.lr = flags.initial_lr\n",
        "\t\tself.lr_decay = flags.lr_decay\n",
        "\t\tself.lr_decay_epoch = flags.lr_decay_epoch\n",
        "\t\tself.beta1 = flags.beta1\n",
        "\t\tself.beta2 = flags.beta2\n",
        "\t\tself.momentum = flags.momentum\n",
        "\t\tself.feature_num = flags.feature_num\n",
        "\t\tself.cnn_size = flags.cnn_size\n",
        "\t\tself.cnn_stride = 1\n",
        "\t\tself.inference_depth = flags.inference_depth\n",
        "\t\tself.batch_num = flags.batch_num\n",
        "\t\tself.batch_size = flags.batch_size\n",
        "\t\tself.stride_size = flags.stride_size\n",
        "\t\tself.optimizer = flags.optimizer\n",
        "\t\tself.loss_alpha = flags.loss_alpha\n",
        "\t\tself.loss_alpha_decay = flags.loss_alpha / flags.loss_alpha_zero_epoch\n",
        "\t\tself.loss_beta = flags.loss_beta\n",
        "\t\tself.weight_dev = flags.weight_dev\n",
        "\t\tself.initializer = flags.initializer\n",
        "\n",
        "\t\t# Image Processing Parameters\n",
        "\t\tself.scale = flags.scale\n",
        "\t\tself.max_value = flags.max_value\n",
        "\t\tself.channels = flags.channels\n",
        "\t\tself.jpeg_mode = flags.jpeg_mode\n",
        "\t\tself.residual = flags.residual\n",
        "\n",
        "\t\t# Training or Other Parameters\n",
        "\t\tself.checkpoint_dir = flags.checkpoint_dir\n",
        "\t\tself.model_name = model_name\n",
        "\n",
        "\t\t# Debugging or Logging Parameters\n",
        "\t\tself.log_dir = flags.log_dir\n",
        "\t\tself.debug = flags.debug\n",
        "\t\tself.visualize = flags.visualize\n",
        "\t\tself.summary = flags.summary\n",
        "\t\tself.log_weight_image_num = 16\n",
        "\n",
        "\t\t# initializing variables\n",
        "\t\tconfig = tf.ConfigProto()\n",
        "\t\tconfig.gpu_options.allow_growth = False\n",
        "\t\tself.sess = tf.InteractiveSession(config=config)\n",
        "\t\tself.H_conv = (self.inference_depth + 1) * [None]\n",
        "\t\tself.batch_input_images = self.batch_num * [None]\n",
        "\t\tself.batch_true_images = self.batch_num * [None]\n",
        "\n",
        "\t\tself.index_in_epoch = -1\n",
        "\t\tself.epochs_completed = 0\n",
        "\t\tself.min_validation_mse = -1\n",
        "\t\tself.min_validation_epoch = -1\n",
        "\t\tself.step = 0\n",
        "\t\tself.training_psnr = 0\n",
        "\n",
        "\t\tself.psnr_graph_epoch = []\n",
        "\t\tself.psnr_graph_value = []\n",
        "\n",
        "\t\tutil.make_dir(self.log_dir)\n",
        "\t\tutil.make_dir(self.checkpoint_dir)\n",
        "\t\tif flags.initialise_log:\n",
        "\t\t\tutil.clean_dir(self.log_dir)\n",
        "\n",
        "\t\tprint(\"Features:%d Inference Depth:%d Initial LR:%0.5f [%s]\" % \\\n",
        "\t\t      (self.feature_num, self.inference_depth, self.lr, self.model_name))\n",
        "\n",
        "\tdef load_datasets(self, cache_dir, training_filenames, test_filenames, batch_size, stride_size):\n",
        "\t\tself.train = DataSets(cache_dir, training_filenames, self.scale, batch_size, stride_size,\n",
        "\t\t                      channels=self.channels, jpeg_mode=self.jpeg_mode, max_value=self.max_value)\n",
        "\t\tself.test = DataSets(cache_dir, test_filenames, self.scale, batch_size, batch_size,\n",
        "\t\t                     channels=self.channels, jpeg_mode=self.jpeg_mode, max_value=self.max_value)\n",
        "\n",
        "\tdef set_next_epoch(self):\n",
        "\n",
        "\t\tself.loss_alpha = max(0, self.loss_alpha - self.loss_alpha_decay)\n",
        "\n",
        "\t\tself.batch_index = random.sample(range(0, self.train.input.count), self.train.input.count)\n",
        "\t\tself.epochs_completed += 1\n",
        "\t\tself.index_in_epoch = 0\n",
        "\n",
        "\tdef build_training_batch(self):\n",
        "\n",
        "\t\tif self.index_in_epoch < 0:\n",
        "\t\t\tself.batch_index = random.sample(range(0, self.train.input.count), self.train.input.count)\n",
        "\t\t\tself.index_in_epoch = 0\n",
        "\n",
        "\t\tfor i in range(self.batch_num):\n",
        "\t\t\tif self.index_in_epoch >= self.train.input.count:\n",
        "\t\t\t\tself.set_next_epoch()\n",
        "\n",
        "\t\t\tself.batch_input_images[i] = self.train.input.image[self.batch_index[self.index_in_epoch]]\n",
        "\t\t\tself.batch_true_images[i] = self.train.true.image[self.batch_index[self.index_in_epoch]]\n",
        "\t\t\tself.index_in_epoch += 1\n",
        "\n",
        "\tdef build_embedding_graph(self):\n",
        "\n",
        "\t\tself.x = tf.placeholder(tf.float32, shape=[None, None, None, self.channels], name=\"X\")\n",
        "\t\tself.y = tf.placeholder(tf.float32, shape=[None, None, None, self.channels], name=\"Y\")\n",
        "\n",
        "\t\t# H-1 conv\n",
        "\t\twith tf.variable_scope(\"W-1_conv\"):\n",
        "\t\t\tself.Wm1_conv = util.weight([self.cnn_size, self.cnn_size, self.channels, self.feature_num],\n",
        "\t\t\t                            stddev=self.weight_dev, name=\"conv_W\", initializer=self.initializer)\n",
        "\t\t\tself.Bm1_conv = util.bias([self.feature_num], name=\"conv_B\")\n",
        "\t\t\tHm1_conv = util.conv2d_with_bias(self.x, self.Wm1_conv, self.cnn_stride, self.Bm1_conv, add_relu=True, name=\"H\")\n",
        "\n",
        "\t\t# H0 conv\n",
        "\t\twith tf.variable_scope(\"W0_conv\"):\n",
        "\t\t\tself.W0_conv = util.weight([self.cnn_size, self.cnn_size, self.feature_num, self.feature_num],\n",
        "\t\t                           stddev=self.weight_dev, name=\"conv_W\", initializer=self.initializer)\n",
        "\t\t\tself.B0_conv = util.bias([self.feature_num], name=\"conv_B\")\n",
        "\t\t\tself.H_conv[0] = util.conv2d_with_bias(Hm1_conv, self.W0_conv, self.cnn_stride, self.B0_conv, add_relu=True,\n",
        "\t\t                                       name=\"H\")\n",
        "\n",
        "\t\tif self.summary:\n",
        "\t\t\t# convert to tf.summary.image format [batch_num, height, width, channels]\n",
        "\t\t\tWm1_transposed = tf.transpose(self.Wm1_conv, [3, 0, 1, 2])\n",
        "\t\t\ttf.summary.image(\"W-1/\" + self.model_name, Wm1_transposed, max_outputs=self.log_weight_image_num)\n",
        "\t\t\tutil.add_summaries(\"B-1\", self.model_name, self.Bm1_conv, mean=True, max=True, min=True)\n",
        "\t\t\tutil.add_summaries(\"W-1\", self.model_name, self.Wm1_conv, mean=True, max=True, min=True)\n",
        "\n",
        "\t\t\tutil.add_summaries(\"B0\", self.model_name, self.B0_conv, mean=True, max=True, min=True)\n",
        "\t\t\tutil.add_summaries(\"W0\", self.model_name, self.W0_conv, mean=True, max=True, min=True)\n",
        "\n",
        "\tdef build_inference_graph(self):\n",
        "\n",
        "\t\tif self.inference_depth <= 0:\n",
        "\t\t\treturn\n",
        "\n",
        "\t\tself.W_conv = util.weight([self.cnn_size, self.cnn_size, self.feature_num, self.feature_num],\n",
        "\t\t                          stddev=self.weight_dev, name=\"W_conv\", initializer=\"diagonal\")\n",
        "\t\tself.B_conv = util.bias([self.feature_num], name=\"B\")\n",
        "\n",
        "\t\tfor i in range(0, self.inference_depth):\n",
        "\t\t\twith tf.variable_scope(\"W%d_conv\" % (i+1)):\n",
        "\t\t\t\tself.H_conv[i + 1] = util.conv2d_with_bias(self.H_conv[i], self.W_conv, 1, self.B_conv, add_relu=True,\n",
        "\t\t\t                                           name=\"H%d\" % i)\n",
        "\n",
        "\t\tif self.summary:\n",
        "\t\t\tutil.add_summaries(\"W\", self.model_name, self.W_conv, mean=True, max=True, min=True)\n",
        "\t\t\tutil.add_summaries(\"B\", self.model_name, self.B_conv, mean=True, max=True, min=True)\n",
        "\n",
        "\tdef build_reconstruction_graph(self):\n",
        "\n",
        "\t\t# HD+1 conv\n",
        "\t\tself.WD1_conv = util.weight([self.cnn_size, self.cnn_size, self.feature_num, self.feature_num],\n",
        "\t\t                            stddev=self.weight_dev, name=\"WD1_conv\", initializer=self.initializer)\n",
        "\t\tself.BD1_conv = util.bias([self.feature_num], name=\"BD1\")\n",
        "\n",
        "\t\t# HD+2 conv\n",
        "\t\tself.WD2_conv = util.weight([self.cnn_size, self.cnn_size, self.feature_num+1, self.channels],\n",
        "\t\t                            stddev=self.weight_dev, name=\"WD2_conv\", initializer=self.initializer)\n",
        "\t\tself.BD2_conv = util.bias([1], name=\"BD2\")\n",
        "\n",
        "\t\tself.Y1_conv = (self.inference_depth) * [None]\n",
        "\t\tself.Y2_conv = (self.inference_depth) * [None]\n",
        "\t\tself.W = tf.Variable(\n",
        "\t\t\tnp.full(fill_value=1.0 / self.inference_depth, shape=[self.inference_depth], dtype=np.float32),\n",
        "\t\tname=\"LayerWeights\")\n",
        "\t\tW_sum = tf.reduce_sum(self.W)\n",
        "\n",
        "\t\tself.y_outputs = self.inference_depth * [None]\n",
        "\n",
        "\t\tfor i in range(0, self.inference_depth):\n",
        "\t\t\twith tf.variable_scope(\"Y%d\" % (i+1)):\n",
        "\t\t\t\tself.Y1_conv[i] = util.conv2d_with_bias(self.H_conv[i+1], self.WD1_conv, self.cnn_stride, self.BD1_conv,\n",
        "\t\t\t\t                                        add_relu=not self.residual, name=\"conv_1\")\n",
        "\t\t\t\ty_conv = tf.concat([self.Y1_conv[i], self.x], 3)\n",
        "\t\t\t\tself.Y2_conv[i] = util.conv2d_with_bias(y_conv, self.WD2_conv, self.cnn_stride, self.BD2_conv,\n",
        "\t\t\t\t                                        add_relu=not self.residual, name=\"conv_2\")\n",
        "\t\t\t\tself.y_outputs[i] = self.Y2_conv[i] * self.W[i] / W_sum\n",
        "\n",
        "\t\tif self.summary:\n",
        "\t\t\tutil.add_summaries(\"BD1\", self.model_name, self.BD1_conv)\n",
        "\t\t\tutil.add_summaries(\"WD1\", self.model_name, self.WD1_conv, mean=True, max=True, min=True)\n",
        "\t\t\tutil.add_summaries(\"WD2\", self.model_name, self.WD2_conv, mean=True, max=True, min=True)\n",
        "\n",
        "\tdef build_optimizer(self):\n",
        "\n",
        "\t\tself.lr_input = tf.placeholder(tf.float32, shape=[], name=\"LearningRate\")\n",
        "\t\tself.loss_alpha_input = tf.placeholder(tf.float32, shape=[], name=\"Alpha\")\n",
        "\n",
        "\t\twith tf.variable_scope(\"Loss\"):\n",
        "\n",
        "\t\t\tself.y_ = tf.add_n(self.y_outputs)\n",
        "\t\t\tif self.residual:\n",
        "\t\t\t\tself.y_ = self.y_ + self.x\n",
        "\n",
        "\t\t\tmse = tf.reduce_mean(tf.square(self.y_ - self.y), name=\"MSE\")\n",
        "\n",
        "\t\tif self.debug:\n",
        "\t\t\tmse = tf.Print(mse, [mse], message=\"MSE: \")\n",
        "\n",
        "\t\ttf.summary.scalar(\"test_PSNR/\" + self.model_name, self.get_psnr_tensor(mse))\n",
        "\n",
        "\t\tif self.loss_alpha == 0.0 or self.inference_depth == 0:\n",
        "\t\t\tloss = mse\n",
        "\t\telse:\n",
        "\n",
        "\t\t\t# we define 'Alpha Loss' as the MSE of internal H1 to Hn\n",
        "\t\t\talpha_mses = (self.inference_depth) * [None]\n",
        "\n",
        "\t\t\twith tf.variable_scope(\"Alpha_Losses\"):\n",
        "\t\t\t\tfor i in range(0, self.inference_depth):\n",
        "\t\t\t\t\twith tf.variable_scope(\"Alpha_Loss%d\" % (i+1)):\n",
        "\t\t\t\t\t\tif self.residual:\n",
        "\t\t\t\t\t\t\tself.Y2_conv[i] = self.Y2_conv[i] + self.x\n",
        "\t\t\t\t\t\tinference_square = tf.square(tf.subtract(self.y, self.Y2_conv[i]))\n",
        "\t\t\t\t\t\talpha_mses[i] = tf.reduce_mean(inference_square)\n",
        "\n",
        "\t\t\t\talpha_loss = tf.add_n(alpha_mses)\n",
        "\t\t\t\talpha_loss = tf.multiply(1.0 / self.inference_depth, alpha_loss, name=\"loss1_weight\")\n",
        "\t\t\t\talpha_loss2 = tf.multiply(self.loss_alpha_input, alpha_loss, name=\"loss1_alpha\")\n",
        "\n",
        "\t\t\t\tif self.visualize:\n",
        "\t\t\t\t\ttf.summary.scalar(\"loss_alpha/\" + self.model_name, alpha_loss)\n",
        "\t\t\t\t\ttf.summary.scalar(\"loss_mse/\" + self.model_name, mse)\n",
        "\n",
        "\t\t\tmse2 = tf.multiply(1 - self.loss_alpha_input, mse, name=\"loss_mse_alpha\")\n",
        "\t\t\tloss = mse2 + alpha_loss2\n",
        "\n",
        "\t\t\tif self.loss_beta > 0.0:\n",
        "\t\t\t\twith tf.variable_scope(\"L2_norms\"):\n",
        "\t\t\t\t\tL2_norm = tf.nn.l2_loss(self.Wm1_conv) + tf.nn.l2_loss(self.W0_conv) \\\n",
        "\t\t\t\t\t        + tf.nn.l2_loss(self.W_conv) + tf.nn.l2_loss(self.WD1_conv) \\\n",
        "\t\t\t\t\t        + tf.nn.l2_loss(self.WD2_conv)\n",
        "\t\t\t\t\tL2_norm *= self.loss_beta\n",
        "\t\t\t\tloss += L2_norm\n",
        "\n",
        "\t\t\t\tif self.visualize:\n",
        "\t\t\t\t\ttf.summary.scalar(\"loss_L2_norm/\" + self.model_name, L2_norm)\n",
        "\n",
        "\t\tif self.visualize:\n",
        "\t\t\ttf.summary.scalar(\"test_loss/\" + self.model_name, loss)\n",
        "\n",
        "\t\tself.loss = loss\n",
        "\t\tself.mse = mse\n",
        "\t\tself.train_step = self.add_optimizer_op(loss, self.lr_input)\n",
        "\n",
        "\t\tutil.print_num_of_total_parameters()\n",
        "\n",
        "\tdef get_psnr_tensor(self, mse):\n",
        "\n",
        "\t\twith tf.variable_scope(\"get_PSNR\"):\n",
        "\t\t\tvalue = tf.constant(self.max_value, dtype=mse.dtype) / tf.sqrt(mse)\n",
        "\t\t\tnumerator = tf.log(value)\n",
        "\t\t\tdenominator = tf.log(tf.constant(10, dtype=mse.dtype))\n",
        "\t\t\treturn tf.constant(20, dtype=mse.dtype) * numerator / denominator\n",
        "\n",
        "\tdef add_optimizer_op(self, loss, lr_input):\n",
        "\n",
        "\t\tif self.optimizer == \"gd\":\n",
        "\t\t\ttrain_step = tf.train.GradientDescentOptimizer(lr_input).minimize(loss)\n",
        "\t\telif self.optimizer == \"adadelta\":\n",
        "\t\t\ttrain_step = tf.train.AdadeltaOptimizer(lr_input).minimize(loss)\n",
        "\t\telif self.optimizer == \"adagrad\":\n",
        "\t\t\ttrain_step = tf.train.AdagradOptimizer(lr_input).minimize(loss)\n",
        "\t\telif self.optimizer == \"adam\":\n",
        "\t\t\ttrain_step = tf.train.AdamOptimizer(lr_input, beta1=self.beta1, beta2=self.beta2).minimize(loss)\n",
        "\t\telif self.optimizer == \"momentum\":\n",
        "\t\t\ttrain_step = tf.train.MomentumOptimizer(lr_input, self.momentum).minimize(loss)\n",
        "\t\telif self.optimizer == \"rmsprop\":\n",
        "\t\t\ttrain_step = tf.train.RMSPropOptimizer(lr_input, momentum=self.momentum).minimize(loss)\n",
        "\t\telse:\n",
        "\t\t\tprint(\"Optimizer arg should be one of [gd, adagrad, adam, momentum, rmsprop].\")\n",
        "\t\t\treturn None\n",
        "\n",
        "\t\treturn train_step\n",
        "\n",
        "\tdef init_all_variables(self, load_initial_data=False):\n",
        "\n",
        "\t\tif self.visualize:\n",
        "\t\t\tself.summary_op = tf.summary.merge_all()\n",
        "\t\t\tself.summary_writer = tf.summary.FileWriter(self.log_dir, graph=self.sess.graph)\n",
        "\n",
        "\t\tself.sess.run(tf.global_variables_initializer())\n",
        "\t\tself.saver = tf.train.Saver()\n",
        "\n",
        "\t\tif load_initial_data:\n",
        "\t\t\tself.saver.restore(self.sess, self.checkpoint_dir + \"/\" + self.model_name + \".ckpt\")\n",
        "\t\t\tprint(\"Model restored.\")\n",
        "\n",
        "\t\tself.start_time = time.time()\n",
        "\n",
        "\tdef train_batch(self, log_mse=False):\n",
        "\n",
        "\t\t_, mse = self.sess.run([self.train_step, self.mse], feed_dict={self.x: self.batch_input_images,\n",
        "\t\t                                                               self.y: self.batch_true_images,\n",
        "\t\t                                                               self.lr_input: self.lr,\n",
        "\t\t                                                               self.loss_alpha_input: self.loss_alpha})\n",
        "\t\tself.step += 1\n",
        "\t\tself.training_psnr = util.get_psnr(mse, max_value=self.max_value)\n",
        "\n",
        "\tdef evaluate(self):\n",
        "\n",
        "\t\tsummary_str, mse = self.sess.run([self.summary_op, self.mse],\n",
        "\t\t                                 feed_dict={self.x: self.test.input.image,\n",
        "\t\t                                            self.y: self.test.true.image,\n",
        "\t\t                                            self.loss_alpha_input: self.loss_alpha})\n",
        "\n",
        "\t\tself.summary_writer.add_summary(summary_str, self.step)\n",
        "\t\tself.summary_writer.flush()\n",
        "\n",
        "\t\tif self.min_validation_mse < 0 or self.min_validation_mse > mse:\n",
        "\t\t\tself.min_validation_epoch = self.epochs_completed\n",
        "\t\t\tself.min_validation_mse = mse\n",
        "\t\telse:\n",
        "\t\t\tif self.epochs_completed > self.min_validation_epoch + self.lr_decay_epoch:\n",
        "\t\t\t\tself.min_validation_epoch = self.epochs_completed\n",
        "\t\t\t\tself.min_validation_mse = mse\n",
        "\t\t\t\tself.lr *= self.lr_decay\n",
        "\n",
        "\t\tpsnr = util.get_psnr(mse, max_value=self.max_value)\n",
        "\t\tself.psnr_graph_epoch.append(self.epochs_completed)\n",
        "\t\tself.psnr_graph_value.append(psnr)\n",
        "\n",
        "\t\treturn mse\n",
        "\n",
        "\tdef save_summary(self):\n",
        "\n",
        "\t\tsummary_str = self.sess.run(self.summary_op,\n",
        "\t\t                            feed_dict={self.x: self.test.input.image,\n",
        "\t\t                                       self.y: self.test.true.image,\n",
        "\t\t                                       self.loss_alpha_input: self.loss_alpha})\n",
        "\n",
        "\t\tself.summary_writer.add_summary(summary_str, 0)\n",
        "\t\tself.summary_writer.flush()\n",
        "\n",
        "\tdef print_status(self, mse):\n",
        "\n",
        "\t\tpsnr = util.get_psnr(mse, max_value=self.max_value)\n",
        "\t\tif self.step == 0:\n",
        "\t\t\tprint(\"Initial MSE:%f PSNR:%f\" % (mse, psnr))\n",
        "\t\telse:\n",
        "\t\t\tprocessing_time = (time.time() - self.start_time) / self.step\n",
        "\t\t\tprint(\"%s Step:%d MSE:%f PSNR:%f (%f)\" % (util.get_now_date(), self.step, mse, psnr, self.training_psnr))\n",
        "\t\t\tprint(\"Epoch:%d LR:%f \u03b1:%f (%2.2fsec/step)\" % (self.epochs_completed, self.lr, self.loss_alpha, processing_time))\n",
        "\n",
        "\tdef print_weight_variables(self):\n",
        "\n",
        "\t\tutil.print_CNN_weight(self.Wm1_conv)\n",
        "\t\tutil.print_CNN_bias(self.Bm1_conv)\n",
        "\t\tutil.print_CNN_weight(self.W0_conv)\n",
        "\t\tutil.print_CNN_bias(self.B0_conv)\n",
        "\t\tutil.print_CNN_bias(self.W)\n",
        "\n",
        "\tdef save_model(self):\n",
        "\n",
        "\t\tfilename = self.checkpoint_dir + \"/\" + self.model_name + \".ckpt\"\n",
        "\t\tself.saver.save(self.sess, filename)\n",
        "\t\tprint(\"Model saved [%s].\" % filename)\n",
        "\n",
        "\tdef save_all(self):\n",
        "\n",
        "\t\tself.save_model()\n",
        "\n",
        "\t\tpsnr_graph = np.column_stack((np.array(self.psnr_graph_epoch), np.array(self.psnr_graph_value)))\n",
        "\n",
        "\t\tfilename = self.checkpoint_dir + \"/\" + self.model_name + \".csv\"\n",
        "\t\tnp.savetxt(filename, psnr_graph, delimiter=\",\")\n",
        "\t\tprint(\"Graph saved [%s].\" % filename)\n",
        "\n",
        "\tdef do(self, input_image):\n",
        "\n",
        "\t\tif len(input_image.shape) == 2:\n",
        "\t\t\tinput_image = input_image.reshape(input_image.shape[0], input_image.shape[1], 1)\n",
        "\n",
        "\t\timage = np.multiply(input_image, self.max_value / 255.0)\n",
        "\t\timage = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n",
        "\t\ty = self.sess.run(self.y_, feed_dict={self.x: image})\n",
        "\n",
        "\t\treturn np.multiply(y[0], 255.0 / self.max_value)\n",
        "\n",
        "\tdef do_super_resolution(self, file_path, output_folder=\"output\"):\n",
        "\n",
        "\t\tfilename, extension = os.path.splitext(file_path)\n",
        "\t\toutput_folder = output_folder + \"/\"\n",
        "\t\torg_image = util.load_image(file_path)\n",
        "\t\tutil.save_image(output_folder + file_path, org_image)\n",
        "\n",
        "\t\tif len(org_image.shape) >= 3 and org_image.shape[2] == 3 and self.channels == 1:\n",
        "\t\t\tscaled_image = util.resize_image_by_pil_bicubic(org_image, self.scale)\n",
        "\t\t\tutil.save_image(output_folder + filename + \"_bicubic\" + extension, scaled_image)\n",
        "\t\t\tinput_ycbcr_image = util.convert_rgb_to_ycbcr(scaled_image, jpeg_mode=self.jpeg_mode)\n",
        "\t\t\toutput_y_image = self.do(input_ycbcr_image[:, :, 0:1])\n",
        "\t\t\tutil.save_image(output_folder + filename + \"_result_y\" + extension, output_y_image)\n",
        "\n",
        "\t\t\timage = util.convert_y_and_cbcr_to_rgb(output_y_image, input_ycbcr_image[:, :, 1:3], jpeg_mode=self.jpeg_mode)\n",
        "\t\telse:\n",
        "\t\t\tscaled_image = util.resize_image_by_pil_bicubic(org_image, self.scale)\n",
        "\t\t\tutil.save_image(output_folder + filename + \"_bicubic\" + extension, scaled_image)\n",
        "\t\t\timage = self.do(scaled_image)\n",
        "\n",
        "\t\tutil.save_image(output_folder + filename + \"_result\" + extension, image)\n",
        "\t\treturn 0\n",
        "\n",
        "\tdef do_super_resolution_for_test(self, file_path, output_folder=\"output\", output=True):\n",
        "\n",
        "\t\tfilename, extension = os.path.splitext(file_path)\n",
        "\t\toutput_folder = output_folder + \"/\"\n",
        "\t\ttrue_image = util.set_image_alignment(util.load_image(file_path), self.scale)\n",
        "\n",
        "\t\tif len(true_image.shape) >= 3 and true_image.shape[2] == 3 and self.channels == 1:\n",
        "\t\t\tinput_y_image = util.build_input_image(true_image, channels=self.channels, scale=self.scale, alignment=self.scale,\n",
        "\t\t\t                                       convert_ycbcr=True, jpeg_mode=self.jpeg_mode)\n",
        "\t\t\ttrue_ycbcr_image = util.convert_rgb_to_ycbcr(true_image, jpeg_mode=self.jpeg_mode)\n",
        "\n",
        "\t\t\toutput_y_image = self.do(input_y_image)\n",
        "\t\t\tmse = util.compute_mse(true_ycbcr_image[:, :, 0:1], output_y_image, border_size=self.scale)\n",
        "\n",
        "\t\t\tif output:\n",
        "\t\t\t\toutput_color_image = util.convert_y_and_cbcr_to_rgb(output_y_image, true_ycbcr_image[:, :, 1:3],\n",
        "\t\t\t\t                                                    jpeg_mode=self.jpeg_mode)\n",
        "\t\t\t\tloss_image = util.get_loss_image(true_ycbcr_image[:, :, 0:1], output_y_image, border_size=self.scale)\n",
        "\n",
        "\t\t\t\tutil.save_image(output_folder + file_path, true_image)\n",
        "\t\t\t\tutil.save_image(output_folder + filename + \"_input\" + extension, input_y_image)\n",
        "\t\t\t\tutil.save_image(output_folder + filename + \"_true_y\" + extension, true_ycbcr_image[:, :, 0:1])\n",
        "\t\t\t\tutil.save_image(output_folder + filename + \"_result\" + extension, output_y_image)\n",
        "\t\t\t\tutil.save_image(output_folder + filename + \"_result_c\" + extension, output_color_image)\n",
        "\t\t\t\tutil.save_image(output_folder + filename + \"_loss\" + extension, loss_image)\n",
        "\t\telse:\n",
        "\t\t\tinput_image = util.load_input_image(file_path, channels=1, scale=self.scale, alignment=self.scale)\n",
        "\t\t\toutput_image = self.do(input_image)\n",
        "\t\t\tmse = util.compute_mse(true_image, output_image, border_size=self.scale)\n",
        "\n",
        "\t\t\tif output:\n",
        "\t\t\t\tutil.save_image(output_folder + file_path, true_image)\n",
        "\t\t\t\tutil.save_image(output_folder + filename + \"_result\" + extension, output_image)\n",
        "\n",
        "\t\tprint(\"MSE:%f PSNR:%f\" % (mse, util.get_psnr(mse)))\n",
        "\t\treturn mse\n",
        "\n",
        "\tdef end_train_step(self):\n",
        "\t\tself.total_time = time.time() - self.start_time\n",
        "\n",
        "\tdef print_steps_completed(self):\n",
        "\t\tif self.step <= 0:\n",
        "\t\t\treturn\n",
        "\n",
        "\t\tprocessing_time = self.total_time / self.step\n",
        "\n",
        "\t\th = self.total_time // (60 * 60)\n",
        "\t\tm = (self.total_time - h * 60 * 60) // 60\n",
        "\t\ts = (self.total_time - h * 60 * 60 - m * 60)\n",
        "\n",
        "\t\tprint(\"Finished at Total Epoch:%d Step:%d Time:%02d:%02d:%02d (%0.3fsec/step)\" % (\n",
        "\t\t\tself.epochs_completed, self.step, h, m, s, processing_time))\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}